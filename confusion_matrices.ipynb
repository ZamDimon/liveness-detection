{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6d62f2",
   "metadata": {},
   "source": [
    "## Confusion Matrices Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import random, os\n",
    "\n",
    "# Core imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from skimage.io import imread_collection\n",
    "\n",
    "# Display imports\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable, axes_size\n",
    "\n",
    "# Helper imports\n",
    "from imutils import paths\n",
    "import pickle\n",
    "import shutil\n",
    "import itertools\n",
    "from itertools import cycle\n",
    "\n",
    "def tf_seed(seed=0):\n",
    "    np.random.seed(seed)  # numpy seed\n",
    "    tf.random.set_seed(seed)  # tensorflow seed\n",
    "    random.seed(seed)  # random seed\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = \"1\"\n",
    "    os.environ['TF_CUDNN_DETERMINISM'] = \"1\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b832e448",
   "metadata": {},
   "source": [
    "# MSSpoof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45832a03",
   "metadata": {},
   "source": [
    "Importing the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17179fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"./models/model_MSSpoof.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f918d652",
   "metadata": {},
   "source": [
    "Loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc9b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width = 32\n",
    "input_height = 32\n",
    "n_channels = 3\n",
    "dim = (input_width, input_height)\n",
    "\n",
    "def resize_normalize_image(image):\n",
    "    image = cv2.resize(image, dim)\n",
    "    return image / np.max(image)\n",
    "\n",
    "def get_images(directories, balance_dataset=True, undersampling=False):\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "\n",
    "    classes = 0\n",
    "\n",
    "    images_per_class=[]\n",
    "\n",
    "    tf_seed()\n",
    "\n",
    "    # for each input directory\n",
    "    for i in directories:\n",
    "        list_images = [f for f in os.listdir(i) if os.path.isfile(os.path.join(i, f))]\n",
    "        images_number = len(list_images)\n",
    "        random.Random(20).shuffle(list_images)\n",
    "        # if we use undersampling\n",
    "        if undersampling:\n",
    "            images_number = images_number if ((len(images_per_class) == 0) or (images_number <= images_per_class[-1]))  else images_per_class[-1]\n",
    "        \n",
    "        # to fill tensors we inizialise them\n",
    "        X = np.empty((images_number, input_width, input_height, n_channels))\n",
    "        L = np.empty((images_number))\n",
    "        ipp = 0\n",
    "        for img_name in list_images:\n",
    "            img = os.path.join(i, img_name)\n",
    "            # to get \"balanced dataset\" using undersampling method\n",
    "            if (balance_dataset and undersampling) and len(images_per_class)  and ipp == images_per_class[-1]:\n",
    "                break\n",
    "\n",
    "            image = cv2.imread(img)\n",
    "            image = resize_normalize_image(image)\n",
    "\n",
    "            X[ipp, ..., :3] = image # each original image is rgb\n",
    "            L[ipp] = classes  # 0 for real, 1 for fake for binary classification\n",
    "\n",
    "            ipp += 1\n",
    "        \n",
    "        # check if the current class has lower images than the before\n",
    "        # in this case we undersample the majority class randomly removing elements\n",
    "        # we will have a balanced dataset: same images for all the classes\n",
    "\n",
    "        if balance_dataset and undersampling:\n",
    "            if len(images_per_class) and ipp < images_per_class[-1]:\n",
    "                left_shift = 0\n",
    "                \n",
    "                for i in range(0, len(images_per_class)):\n",
    "                    diff = images_per_class[i] - ipp\n",
    "\n",
    "                    for j in range(0, diff):\n",
    "                        random_index = np.random.randint(left_shift, images_per_class[i] - j)\n",
    "                        image_list.pop(random_index)\n",
    "                        label_list.pop(random_index)\n",
    "                        \n",
    "                    left_shift += images_per_class[i] - diff\n",
    "\n",
    "        if undersampling or balance_dataset == False:\n",
    "            for image in X:\n",
    "                image_list.append(image)\n",
    "\n",
    "            for label in L:\n",
    "                label_list.append(label)\n",
    "        else:\n",
    "            image_array=[]\n",
    "            label_array=[]\n",
    "            \n",
    "            for image in X:\n",
    "                image_array.append(image)\n",
    "\n",
    "            image_list.append(np.array(image_array, dtype=\"float\"))\n",
    "\n",
    "             \n",
    "            for label in L:\n",
    "                label_array.append(label)\n",
    "\n",
    "            label_list.append(label_array)\n",
    "\n",
    "        if undersampling or balance_dataset == False:\n",
    "            images_per_class.append(ipp)\n",
    "        else:\n",
    "            images_per_class.append(images_number)\n",
    "\n",
    "        classes += 1\n",
    "\n",
    "    # offline augmentation\n",
    "    if balance_dataset and undersampling==False:\n",
    "        _max = np.max((images_per_class)) #[4k,3k,2k,1k]\n",
    "\n",
    "        for j in range(0, len(images_per_class)):  #[[4k], [4k], [4k], [4k]]\n",
    "            if images_per_class[j] < _max:\n",
    "                diff = _max - images_per_class[j] #how many images to generate\n",
    "\n",
    "                image_array = image_list[j]   #[3k]\n",
    "                label_array = label_list[j]   #[3k]\n",
    "\n",
    "                new_image_array = []\n",
    "             \n",
    "                offline_generator = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "                    width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "                    horizontal_flip=True, fill_mode=\"constant\")\n",
    "\n",
    "\n",
    "                offline_generator = offline_generator.flow(image_array, batch_size=1, seed = 2)\n",
    "\n",
    "                # generate the reamining images respect the majority class, to balance the dataset\n",
    "                generated_images = 0\n",
    "                \n",
    "                while generated_images < diff:     \n",
    "                    for i in range(0,len(offline_generator)):\n",
    "                        if generated_images == diff:\n",
    "                            break\n",
    "                            \n",
    "                        batch = next(offline_generator)\n",
    "                        new_image_array.append(batch[0])\n",
    "                        label_array.append(j)\n",
    "                        generated_images += 1\n",
    "\n",
    "            \n",
    "     \n",
    "                image_list[j]=np.append(image_list[j], new_image_array, axis=0)\n",
    "\n",
    "         # image_list and label_list were of type [[...], [...]] for attack and bonafide classes\n",
    "         # we need a final array of type [image1,image2,...] for images and [0,1,...] for labels\n",
    "            new_image_list= np.empty((0, final_x, final_y, n_channels))\n",
    "            new_label_list=[]\n",
    "\n",
    "\n",
    "            for class_value_array in image_list:\n",
    "                new_image_list = np.vstack((new_image_list,class_value_array))\n",
    "\n",
    "            for class_value_array in label_list:\n",
    "                new_label_list += class_value_array\n",
    "\n",
    "        image_list = new_image_list\n",
    "        label_list = new_label_list\n",
    "\n",
    "        print(image_list.shape)\n",
    "        print(len(label_list))\n",
    "         \n",
    "        # im_show(new_image_list[2]) # we can show up an image \n",
    "      \n",
    "        \n",
    "    #create the one-hot encoded vector: [0 1], [1 0]\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(label_list)\n",
    "    labels = tf.keras.utils.to_categorical(labels, 2)\n",
    "\n",
    "    if type(image_list) is np.ndarray:\n",
    "        return image_list, labels, le\n",
    "    return np.array(image_list, dtype=\"float\"), labels, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b275d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "msspoof_dataset_path = './datasets/MSSpoof/MSSpoof_dataset/images'\n",
    "attack = f'{msspoof_dataset_path}/attack_validation'\n",
    "bonifade = f'{msspoof_dataset_path}/bonifade_validation'\n",
    "\n",
    "X_test, Y_test, _ = get_images([bonifade, attack], undersampling=True)\n",
    "Y_test = np.argmax(Y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba2044",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f1c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = X_test[10].reshape((1,32,32,3))\n",
    "sample_label = Y_test[10]\n",
    "\n",
    "plt.imshow(sample[0])\n",
    "print('Label:', 'Real' if sample_label == 0 else 'Fake')\n",
    "\n",
    "prediction = model.predict(sample, verbose=0)\n",
    "print(f'{prediction[0][0]} for being real\\n{prediction[0][1]} for being fake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d095fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_score = model.predict(X_test, verbose=0)\n",
    "Y_pred = np.argmax(Y_score, axis=1)\n",
    "\n",
    "for (prediction, real) in list(zip(Y_pred[100:110], Y_test[100:110])):\n",
    "    print(f'Prediction: {prediction}, real: {real}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c4f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    def precision(index):\n",
    "        return round(cm[index][index] / cm[:, index].sum(),2)\n",
    "\n",
    "    def recall(index):\n",
    "        return round(cm[index][index] /cm[index].sum(),2)\n",
    "\n",
    "    def F1_score(index):\n",
    "        p=precision(index)\n",
    "        r=recall(index)\n",
    "        return round((2 * p * r)/(p + r),2)\n",
    "\n",
    "    plt.figure(figsize=(6, 6), dpi=80)\n",
    "\n",
    "    im = plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, round(cm[i, j],2),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "\n",
    "    #### CREATE THE PRECISION / RECALL / F1_SCORE TABLE ####\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 2 + 3 / 2.5))\n",
    "\n",
    "    col_labels=[\"Bonafide\", \"Attacker\"]\n",
    "    row_labels=['Precision','Recall','F1 Score']\n",
    "    row_func=[precision,recall,F1_score]\n",
    "    table_vals=[]\n",
    "\n",
    "    row_colors = np.full(len(row_labels), 'linen')\n",
    "    col_colors = np.full(len(col_labels), 'lavender')\n",
    "\n",
    "\n",
    "    for i in range(0, len(row_labels)):\n",
    "        row=[]\n",
    "\n",
    "        for j in range(0, len(col_labels)):\n",
    "            row.append(row_func[i](j))\n",
    "\n",
    "        table_vals.append(row)\n",
    "\n",
    "\n",
    "    # the rectangle is where I want to place the table\n",
    "    table = plt.table(cellText=table_vals,\n",
    "                  cellLoc='center',\n",
    "                  rowColours=row_colors,\n",
    "                  rowLabels=row_labels,\n",
    "                  rowLoc='center',\n",
    "                  colColours=col_colors,\n",
    "                  colLabels=col_labels,\n",
    "                  loc='center')\n",
    "    table.scale(1, 2)\n",
    "    ax1.axis('off')\n",
    "\n",
    "class_names = {\"Bonafide\", \"Attacker\"}\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e3b52",
   "metadata": {},
   "source": [
    "## Using 3DMAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed190fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"./models/model_MSSpoof.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ee0c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_normalize_image(image, value=255):\n",
    "    image=cv2.resize(image, dim)\n",
    "    return image / value\n",
    "\n",
    "#return file name given a path\n",
    "def get_file_name(path):\n",
    "    base = os.path.basename(path)\n",
    "    return os.path.splitext(base)[0]\n",
    "\n",
    "def get_images(directories, mask=True, balance_dataset=True, undersampling=False):\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    classes = 0\n",
    "    images_per_class=[]\n",
    "    tf_seed()\n",
    "\n",
    "    #for each input directory\n",
    "    for i in directories:\n",
    "        list_images = [f for f in os.listdir(i) if os.path.isfile(os.path.join(i, f))]\n",
    "        images_number = len(list_images)\n",
    "        random.Random(20).shuffle(list_images)\n",
    "        \n",
    "        # if we use undersampling\n",
    "        if undersampling:\n",
    "            images_number = images_number if ((len(images_per_class) == 0) or (images_number <= images_per_class[-1]))  else images_per_class[-1]\n",
    "        \n",
    "        # to fill tensors we inizialise them\n",
    "        X = np.empty((images_number, final_x, final_y, n_channels))\n",
    "        L = np.empty((images_number))\n",
    "        ipp = 0\n",
    "        \n",
    "        for im_name in list_images:\n",
    "            im=os.path.join(i, im_name)\n",
    "            # to get \"balanced dataset\" using undersampling method\n",
    "            if (balance_dataset and undersampling) and len(images_per_class)  and ipp == images_per_class[-1]:\n",
    "                break\n",
    "\n",
    "            image = cv2.imread(im)\n",
    "            image = resize_normalize_image(image, value=255)\n",
    "        \n",
    "            if mask:\n",
    "                mask_name = os.path.join(\n",
    "                    i, \"mask\", get_file_name(im) + \"_mask.npy\")\n",
    "                image_mask = np.load(mask_name)\n",
    "                image_mask = resize_normalize_image(image_mask, value=2048)  #since 3DMAD mask is rgb 2^1        \n",
    "\n",
    "            X[ipp, ..., :3] = image # each original image is rgb\n",
    "            \n",
    "            if mask:\n",
    "                print(np.shape(image_mask))\n",
    "                X[ipp, ..., 3] = image_mask # each mask can be n_channels - 3\n",
    "\n",
    "            L[ipp] = classes  # 0 for real, 1 for fake for binary classification\n",
    "\n",
    "            ipp += 1\n",
    "        \n",
    "        # check if the current class has lower images than the before\n",
    "        # in this case we undersample the majority class randomly removing elements\n",
    "        # we will have a balanced dataset: same images for all the classes\n",
    "\n",
    "        if balance_dataset and undersampling:\n",
    "            if len(images_per_class) and ipp < images_per_class[-1]:\n",
    "                left_shift = 0\n",
    "                \n",
    "                for i in range(0, len(images_per_class)):\n",
    "                    diff = images_per_class[i] - ipp\n",
    "\n",
    "                    for j in range(0, diff):\n",
    "                        random_index = np.random.randint(left_shift, images_per_class[i] - j)\n",
    "                        image_list.pop(random_index)\n",
    "                        label_list.pop(random_index)\n",
    "\n",
    "                    left_shift += images_per_class[i] - diff\n",
    "\n",
    "        if undersampling or balance_dataset==False:\n",
    "            for image in X:\n",
    "                image_list.append(image)\n",
    "\n",
    "            for label in L:\n",
    "                label_list.append(label)\n",
    "        else:\n",
    "            image_array=[]\n",
    "            label_array=[]\n",
    "            \n",
    "            for image in X:\n",
    "                image_array.append(image)\n",
    "\n",
    "            image_list.append(np.array(image_array, dtype=\"float\"))\n",
    " \n",
    "            for label in L:\n",
    "                label_array.append(label)\n",
    "            \n",
    "            label_list.append(label_array)\n",
    "\n",
    "        if undersampling or balance_dataset==False:\n",
    "            images_per_class.append(ipp)\n",
    "        else:\n",
    "            images_per_class.append(images_number)\n",
    "\n",
    "        classes += 1\n",
    "\n",
    "    #offline augmentation\n",
    "    if balance_dataset and undersampling==False:\n",
    "        _max = np.max((images_per_class)) #[4k,3k,2k,1k]\n",
    "\n",
    "        for j in range(0, len(images_per_class)):  #[[4k], [4k], [4k], [4k]]\n",
    "            if images_per_class[j] < _max:\n",
    "                diff= _max - images_per_class[j] #how many images to generate\n",
    "\n",
    "                image_array=image_list[j]   #[3k]\n",
    "                label_array=label_list[j]   #[3k]\n",
    "\n",
    "                new_image_array=[]\n",
    "             \n",
    "\n",
    "                # use ImageDataGenerator \n",
    "                offline_generator = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "                    width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "                    horizontal_flip=True, fill_mode=\"constant\")\n",
    "\n",
    "\n",
    "                offline_generator = offline_generator.flow(image_array, batch_size=1, seed=20)\n",
    "\n",
    "                # generate the reamining images respect the majority class, to balance the dataset\n",
    "                generated_images=0\n",
    "                while generated_images < diff:     \n",
    "                    for i in range(0,len(offline_generator)):\n",
    "                        if generated_images == diff:\n",
    "                            break\n",
    "                        batch = next(offline_generator)\n",
    "                        new_image_array.append(batch[0])\n",
    "                        label_array.append(j)\n",
    "                        generated_images += 1\n",
    "\n",
    "                print(generated_images)\n",
    "                image_list[j]=np.append(image_list[j], new_image_array, axis=0)\n",
    "\n",
    "                # image_list and label_list were of type [[...], [...]] for attack and bonafide classes\n",
    "                # we need a final array of type [image1,image2,...] for images and [0,1,...] for labels\n",
    "\n",
    "            new_image_list= np.empty((0, final_x, final_y, n_channels))\n",
    "            new_label_list=[]\n",
    "\n",
    "\n",
    "        for class_value_array in image_list:\n",
    "            new_image_list = np.vstack((new_image_list,class_value_array))\n",
    "\n",
    "        for class_value_array in label_list:\n",
    "            new_label_list += class_value_array\n",
    "\n",
    "        image_list = new_image_list\n",
    "        label_list = new_label_list\n",
    "\n",
    "        print(image_list.shape)\n",
    "        print(len(label_list)) \n",
    "        # im_show(new_image_list[2]) # we can show up an image \n",
    "      \n",
    "        \n",
    "    #create the one-hot encoded vector: [0 1], [1 0]\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(label_list)\n",
    "    labels = tf.keras.utils.to_categorical(labels, 2)\n",
    "\n",
    "    if type(image_list) is np.ndarray:\n",
    "        return image_list, labels, le\n",
    "    \n",
    "    return np.array(image_list, dtype=\"float\"), labels, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b281be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "msspoof_dataset_path = './datasets/3DMAD/3DMAD/images'\n",
    "attack = f'{msspoof_dataset_path}/attack_validation'\n",
    "bonifade = f'{msspoof_dataset_path}/bonifade_validation'\n",
    "\n",
    "X_test, Y_test, _ = get_images([bonifade, attack], undersampling=True, mask=False)\n",
    "Y_test = np.argmax(Y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c5350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = X_test[0].reshape((1,32,32,3))\n",
    "sample_label = Y_test[0]\n",
    "\n",
    "plt.imshow(sample[0])\n",
    "print('Label:', 'Real' if sample_label == 0 else 'Fake')\n",
    "\n",
    "prediction = model.predict(sample, verbose=0)\n",
    "print(f'{prediction[0][0]} for being real\\n{prediction[0][1]} for being fake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb1301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_score = model.predict(X_test, verbose=0)\n",
    "Y_pred = np.argmax(Y_score, axis=1)\n",
    "\n",
    "for (prediction, real) in list(zip(Y_pred[100:110], Y_test[100:110])):\n",
    "    print(f'Prediction: {prediction}, real: {real}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56924dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {\"Bonafide\", \"Attacker\"}\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f880008f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
